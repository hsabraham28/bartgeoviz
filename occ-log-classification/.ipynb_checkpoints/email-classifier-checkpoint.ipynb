{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0b49a2ae-a31b-423c-94dd-1c85eb11b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import docx\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "97208aa9-c606-433c-ae1c-d9cb34745e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    'train.csv',\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='spam',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5a2af9cd-3624-47c1-b4c8-7af9fd681064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = csv_ds.take(1200)\n",
    "val_ds = csv_ds.skip(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c490b268-ee8c-4072-bdc8-c50f598ec213",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c273880c-87f1-42ad-a143-dd5255c9fd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (OrderedDict([(id, (None,)), (subject, (None,)), (email, (None,))]), (None,)), types: (OrderedDict([(id, tf.int32), (subject, tf.string), (email, tf.string)]), tf.int32)>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c4408f4c-c340-4bc0-aeab-ad2c168f70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a 1,000 word vocabulary into 5 dimensions.\n",
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "defbf800-7508-4f58-918c-bd6076978d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3287ff36-f299-4094-bef4-80fcab9d78b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (None,), types: tf.string>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x['email'])\n",
    "vectorize_layer.adapt(text_ds)\n",
    "\n",
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b8db35f2-2c66-4b66-9b13-86c14e9efac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  GlobalAveragePooling1D(),\n",
    "  Dense(16, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0934cd0a-99d9-4a3b-b551-b9f386d8c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c859d60e-3280-46f2-b699-70ae2e823303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "77fe1e42-1aa7-4244-877a-804d7cc564c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9966\n",
      "Epoch 2/5\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0161 - val_accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0163 - val_accuracy: 0.9957\n",
      "Epoch 4/5\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0169 - val_accuracy: 0.9957\n",
      "Epoch 5/5\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0178 - val_accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36c051bb50>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "80990460-f20e-4f43-a092-a59bf9252530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_23 (TextV (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 16)           16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 16,289\n",
      "Trainable params: 16,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f73e7-e4bb-4d82-b7fd-925d0e82e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59936fb-758e-4c43-8740-a0650142617d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80eac3-7eec-493d-8183-c08895b71950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "conda-env-py38_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
